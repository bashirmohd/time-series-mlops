name: Train and Deploy

on:
  push:
    branches:
      - master
  schedule:
    - cron:  '0 8 * * MON-FRI'

jobs: 
  train:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2

    - name: Setup GCP client
      uses: google-github-actions/setup-gcloud@master 

    - id: auth
      uses: google-github-actions/auth@v0.4.0
      with:
        credentials_json: ${{ secrets.GCP_CREDENTIALS }}

    - id: 'gcloud'
      name: 'gcloud'
      run: |-
        gcloud auth login --brief --cred-file="${{ steps.auth.outputs.credentials_file_path }}" 

    - name: Use gcloud CLI
      run: gcloud info 
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v2
      with:
        python-version: 3.7
    
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt 
    
    - name: Download the latest datasets 
      run: |
        gsutil cp gs://pipeline-automation/time-series/throughput_metrics.csv datasets/throughput_metrics.csv

    - name: Run training task
      run: |
        python steps/train.py --path=datasets/throughput_metrics.csv 

    - name: Upload new model and associated metrics
      run: |
        gsutil cp artifacts/model.joblib gs://pipeline-automation/time-series/models/latest.joblib
        gsutil cp artifacts/model.joblib gs://pipeline-automation/time-series/models/${{ env.GITHUB_RUN_ID }}.joblib
        gsutil cp artifacts/metrics.json gs://pipeline-automation/time-series/models/metrics/${{ env.GITHUB_RUN_ID }}.joblib

    - name: Deploy model as Cloud Function
      run: | 
        gcloud functions deploy time-series --entry-point=predict_handler --runtime=python37 --project=${{ secrets.GCP_PROJECT_ID }} --allow-unauthenticated --trigger-http
